# ä»£ç ä¸è„šæœ¬ Code and Scripts

### training/

é¢„è®­ç»ƒä¸æŒ‡ä»¤ç²¾è°ƒä»£ç ï¼ŒWikiï¼š

- é¢„è®­ç»ƒï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/pt_scripts_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/pt_scripts_zh)
- æŒ‡ä»¤ç²¾è°ƒï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/sft_scripts_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/sft_scripts_zh)

Pre-training and instruction finetuning code, Wiki:

- Pre-training: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/pt_scripts_en
- Instruction finetuning: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/sft_scripts_en

### inference/

ä½¿ç”¨ğŸ¤—transformersè¿›è¡Œæ¨ç†ï¼ŒWikiï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/inference_with_transformers_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/inference_with_transformers_zh)

Inference using ğŸ¤—transformers, Wiki: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/inference_with_transformers_en

### openai_server_demo/

ä½¿ç”¨fastapiå®ç°çš„ä»¿OPENAI APIé£æ ¼çš„æœåŠ¡å™¨ï¼ŒWikiï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/api_calls_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/api_calls_zh)

A server that implements OPENAI API using fastapi, Wiki: [https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/api_calls_en](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/api_calls_en)

### ceval/

C-Evalè¯„æµ‹è„šæœ¬ï¼ŒWikiï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/ceval_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/ceval_zh)

Inference script for C-Eval, Wiki: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/ceval_en

### cmmlu/

CMMLUè¯„æµ‹è„šæœ¬ï¼ŒWikiï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/cmmlu_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/cmmlu_zh)

Inference script for CMMLU, Wiki: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/cmmlu_en

### longbench/

LongBenchè¯„æµ‹è„šæœ¬ï¼ŒWikiï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/longbench_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/longbench_zh)

Inference script for LongBench, Wiki: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/longbench_en

### llama-cpp/

llama.cppå¯åŠ¨è„šæœ¬ã€serverè„šæœ¬ï¼ŒWikiï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/llamacpp_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/llamacpp_zh)

launch script and server script for llama.cpp, Wiki: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/llamacpp_en


### attn_ang_long_ctx_patches.py

Memory efficient attentionè¡¥ä¸å’ŒNTKä¸Šä¸‹æ–‡æ‹“å±•æ–¹æ³•è¡¥ä¸ã€‚

Patches for memory efficient attention and NTK context size scaling.

### merge_llama2_with_chinese_lora_low_mem.py

ä½èµ„æºç‰ˆåˆå¹¶LLaMA-2/Alpaca-2 LoRAè„šæœ¬ï¼ŒWikiï¼š[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/manual_conversion_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/manual_conversion_zh)

Script for merging LLaMA-2/Alpaca-2 LoRA (low-resource version). Wiki: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/manual_conversion_en

### tokenizer/

Chinese-LLaMA-2 & Chinese-Alpaca-2 tokenizer